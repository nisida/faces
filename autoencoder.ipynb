{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D  \n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "random.seed(42)  # @UndefinedVariable\n",
    "\n",
    "from tensorflow.keras.datasets import mnist , fashion_mnist, cifar100\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\"\"\"Autoencoder Simples Model\n",
    "    https://elix-tech.github.io/ja/2016/07/17/autoencoder.html\n",
    "    参考論文 : https://arxiv.org/pdf/1812.11262.pdf\n",
    "      [我々はロバストな予測のためのオートエンコーダーベースの残差ディープネットワークを提案する]\n",
    "\"\"\"\n",
    "\n",
    "CASE = \"mnist\"  # mnist, fashion_mnist, cifar100\n",
    "OBJ  = {\"mnist\":mnist, \"fashion\":fashion_mnist, \"cifar100\":cifar100}\n",
    "\n",
    "# load mnist data\n",
    "(x_train, _), (x_test, _) = OBJ[CASE].load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test.astype('float32') / 255.   \n",
    "ENC_ACT, DEC_ACT = 'relu', 'sigmoid'            \n",
    "    \n",
    "WIDTH, HEIGHT, CL = x_train.shape[1], x_train.shape[2], 1\n",
    "encoding_dim, decoding_dim, EPOCH, BATCH_SIZE = 32, WIDTH * HEIGHT * CL, 60, 64\n",
    " x_train = np.reshape(x_train, [-1, x_train.shape[1] * x_train.shape[2] * CL])\n",
    "x_test  = np.reshape(x_test, [-1, x_test.shape[1] * x_test.shape[2] * CL])\n",
    "\n",
    "print(\"train.shape = {}, test.shape= {}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "    \n",
    "# encode\n",
    "input_img    = Input(shape=(x_train.shape[1], ), name = \"autoencoder\" + \"_input\")\n",
    "\n",
    "#encoded      = Dropout(0.5)(input_img)\n",
    "encoded      = Dense(encoding_dim, activation=ENC_ACT)(input_img)\n",
    "encoded      = Flatten(name='flatten_e1')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation=ENC_ACT)(encoded)\n",
    "encoded      = Flatten(name='flatten_e2')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation=ENC_ACT)(encoded)\n",
    "encoded      = Flatten(name='flatten_e3')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation=ENC_ACT)(encoded)\n",
    "encoded      = Flatten(name='flatten_e4')(encoded)\n",
    "encoded      = Dense(encoding_dim, activation=ENC_ACT)(encoded)  # n = 10\n",
    "# decode\n",
    "decoded      = Dense(decoding_dim, activation=DEC_ACT)(encoded)\n",
    "decoded      = Flatten(name='flatten_d1')(decoded)\n",
    "decoded      = Dense(decoding_dim, activation=DEC_ACT)(decoded)\n",
    "decoded      = Flatten(name='flatten_d2')(decoded)\n",
    "decoded      = Dense(decoding_dim, activation=DEC_ACT)(decoded)\n",
    "decoded      = Flatten(name='flatten_d3')(decoded)\n",
    "decoded      = Dense(decoding_dim, activation=DEC_ACT)(decoded)\n",
    "decoded      = Flatten(name='flatten_d4')(decoded)\n",
    "decoded      = Dense(decoding_dim, activation=DEC_ACT)(decoded)\n",
    "\n",
    "autoencoder  = Model(input_img, decoded)\n",
    "\n",
    "# Opt\n",
    "#Adam\n",
    "#lr: 0以上の浮動小数点数．学習率．\n",
    "#beta_1: 浮動小数点数, 0 < beta < 1. 一般的に1に近い値です．\n",
    "#beta_2: 浮動小数点数, 0 < beta < 1. 一般的に1に近い値です．\n",
    "#epsilon: 0以上の浮動小数点数．微小量．NoneならばデフォルトでK.epsilon()．\n",
    "#decay: 0以上の浮動小数点数．各更新の学習率減衰．\n",
    "#amsgrad: 論文\"On the Convergence of Adam and Beyond\"にあるAdamの変種であるAMSGradを適用するかどうか．\n",
    "\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "\n",
    "# ResourceExhaustedError\n",
    "# https://testpy.hatenablog.com/entry/2017/05/07/122323\n",
    "hist = autoencoder.fit(x_train, x_train, epochs=EPOCH, batch_size=BATCH_SIZE, shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "def results_draw(x_test, decode_imgs, d_size) :\n",
    "      \n",
    "    \"\"\"Draw Autoencoder Results\n",
    "    \"\"\"\n",
    "      \n",
    "    import matplotlib.pyplot as plt\n",
    "      \n",
    "    # 何個表示するか\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # オリジナルのテスト画像を表示\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(d_size[0], d_size[1], d_size[2]))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        # 変換された画像を表示\n",
    "        ax = plt.subplot(2, n, i+1+n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(d_size[0], d_size[1], d_size[2]))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.savefig(\"autoencoder_results.png\")\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "results_draw(x_test, decoded_imgs, (WIDTH, HEIGHT, CL))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
